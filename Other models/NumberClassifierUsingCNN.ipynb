{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28bbf58b-4871-4cb7-84b2-2515cbdba558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee4b9688-cf79-4b1c-97a7-98aee6f1d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0cc95a-6022-4e8c-a8a8-9e459833fa44",
   "metadata": {},
   "source": [
    "<h1>CNN WITH ONE SET OF CONVOLUTIONAL AND POOLING LAYER</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "591394d5-cdeb-406b-a4ef-a9ce92a42243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "xTrain = xTrain.reshape(xTrain.shape[0], 28, 28, 1).astype('float32')\n",
    "xTest = xTest.reshape(xTest.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8de4bb6a-4cc1-4e3f-a629-3f9ab6556307",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = xTrain / 255\n",
    "xTest = xTest / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa440161-1c98-4d55-a659-6797392f246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain = to_categorical(yTrain)\n",
    "yTest = to_categorical(yTest)\n",
    "num_classes = yTest.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6919fae-e94c-4406-991a-d9e626d01e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape = (28, 28, 1)))\n",
    "    model.add(Conv2D(16, (5, 5), strides = (1, 1), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = 'relu'))\n",
    "    model.add(Dense(num_classes, activation = 'softmax'))\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ff88264-30bf-4089-b2d8-afd56ea3b396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 4s - 13ms/step - accuracy: 0.9168 - loss: 0.2956 - val_accuracy: 0.9741 - val_loss: 0.0894\n",
      "Epoch 2/10\n",
      "300/300 - 2s - 8ms/step - accuracy: 0.9761 - loss: 0.0832 - val_accuracy: 0.9824 - val_loss: 0.0584\n",
      "Epoch 3/10\n",
      "300/300 - 2s - 8ms/step - accuracy: 0.9827 - loss: 0.0584 - val_accuracy: 0.9825 - val_loss: 0.0511\n",
      "Epoch 4/10\n",
      "300/300 - 2s - 8ms/step - accuracy: 0.9865 - loss: 0.0449 - val_accuracy: 0.9872 - val_loss: 0.0407\n",
      "Epoch 5/10\n",
      "300/300 - 2s - 8ms/step - accuracy: 0.9884 - loss: 0.0374 - val_accuracy: 0.9862 - val_loss: 0.0420\n",
      "Epoch 6/10\n",
      "300/300 - 2s - 8ms/step - accuracy: 0.9900 - loss: 0.0316 - val_accuracy: 0.9878 - val_loss: 0.0381\n",
      "Epoch 7/10\n",
      "300/300 - 2s - 8ms/step - accuracy: 0.9920 - loss: 0.0268 - val_accuracy: 0.9885 - val_loss: 0.0370\n",
      "Epoch 8/10\n",
      "300/300 - 2s - 8ms/step - accuracy: 0.9933 - loss: 0.0220 - val_accuracy: 0.9884 - val_loss: 0.0365\n",
      "Epoch 9/10\n",
      "300/300 - 2s - 8ms/step - accuracy: 0.9943 - loss: 0.0184 - val_accuracy: 0.9883 - val_loss: 0.0371\n",
      "Epoch 10/10\n",
      "300/300 - 2s - 8ms/step - accuracy: 0.9957 - loss: 0.0154 - val_accuracy: 0.9885 - val_loss: 0.0362\n",
      "Accuracy:  0.9884999990463257 Error:  1.1500000953674316\n"
     ]
    }
   ],
   "source": [
    "model = convolutional_model()\n",
    "model.fit(xTrain, yTrain, validation_data = (xTest, yTest), epochs = 10, batch_size = 200, verbose = 2)\n",
    "scores = model.evaluate(xTest, yTest, verbose = 0)\n",
    "print(\"Accuracy: \", scores[1], \"Error: \", (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f54868d-67f8-4113-baec-3e14ab826635",
   "metadata": {},
   "source": [
    "<h1>CNN WITH TWO SETS OF CONVOLUTIONAL AND POOLING LAYERS</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1362ba56-3c2d-4676-b70e-bd28341ae591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model():\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(28, 28, 1)))\n",
    "    model.add(Conv2D(16, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(8, (2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb996f31-9d6e-48f9-bb30-e90fd1664a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)      (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(xTrain.shape, \"    \", xTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a85f281-0a6c-4c66-992b-ea3906fa0d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 3s - 11ms/step - accuracy: 0.8737 - loss: 0.4648 - val_accuracy: 0.9572 - val_loss: 0.1462\n",
      "Epoch 2/10\n",
      "300/300 - 2s - 6ms/step - accuracy: 0.9619 - loss: 0.1293 - val_accuracy: 0.9728 - val_loss: 0.0867\n",
      "Epoch 3/10\n",
      "300/300 - 2s - 6ms/step - accuracy: 0.9724 - loss: 0.0915 - val_accuracy: 0.9785 - val_loss: 0.0687\n",
      "Epoch 4/10\n",
      "300/300 - 2s - 6ms/step - accuracy: 0.9776 - loss: 0.0739 - val_accuracy: 0.9804 - val_loss: 0.0616\n",
      "Epoch 5/10\n",
      "300/300 - 2s - 6ms/step - accuracy: 0.9811 - loss: 0.0617 - val_accuracy: 0.9828 - val_loss: 0.0503\n",
      "Epoch 6/10\n",
      "300/300 - 2s - 6ms/step - accuracy: 0.9833 - loss: 0.0542 - val_accuracy: 0.9851 - val_loss: 0.0457\n",
      "Epoch 7/10\n",
      "300/300 - 2s - 7ms/step - accuracy: 0.9851 - loss: 0.0480 - val_accuracy: 0.9867 - val_loss: 0.0422\n",
      "Epoch 8/10\n",
      "300/300 - 2s - 6ms/step - accuracy: 0.9866 - loss: 0.0439 - val_accuracy: 0.9872 - val_loss: 0.0400\n",
      "Epoch 9/10\n",
      "300/300 - 2s - 7ms/step - accuracy: 0.9877 - loss: 0.0400 - val_accuracy: 0.9885 - val_loss: 0.0358\n",
      "Epoch 10/10\n",
      "300/300 - 2s - 7ms/step - accuracy: 0.9892 - loss: 0.0353 - val_accuracy: 0.9867 - val_loss: 0.0387\n",
      "Accuracy: 0.9866999983787537 \n",
      " Error: 1.3300001621246338\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model2 = convolutional_model()\n",
    "\n",
    "# fit the model\n",
    "model2.fit(xTrain, yTrain, validation_data=(xTest, yTest), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model2.evaluate(xTest, yTest, verbose=0)\n",
    "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf9cdda1-0c0c-4fab-aa85-45f96d586ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "Predicted Class: 5\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    # Load the image in grayscale mode\n",
    "    image = Image.open(image_path).convert(\"L\")\n",
    "    \n",
    "    # Resize the image to 28x28 pixels\n",
    "    image = image.resize((28, 28))\n",
    "    \n",
    "    # Normalize pixel values (0-255 to 0-1)\n",
    "    image = np.array(image).astype('float32') / 255.0\n",
    "    \n",
    "    # Add batch and channel dimensions to match input shape\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    image = np.expand_dims(image, axis=-1)  # Add channel dimension (for grayscale)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"image.png\"\n",
    "\n",
    "# Preprocess the image\n",
    "processed_image = preprocess_image(image_path)\n",
    "\n",
    "# Show the image\n",
    "plt.imshow(processed_image.squeeze(), cmap=\"gray\")\n",
    "plt.title(\"Input Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Use the model to predict the class\n",
    "predicted_class = model2.predict(processed_image)\n",
    "predicted_label = np.argmax(predicted_class)\n",
    "\n",
    "print(f\"Predicted Class: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7963ab80-347c-4247-9c94-8ad5c1b027ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
